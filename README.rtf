{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;\f1\fswiss\fcharset0 Helvetica;\f2\froman\fcharset0 TimesNewRomanPSMT;
}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww12500\viewh13200\viewkind1
\deftab720
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardeftab720\ri0

\f0\fs24 \cf0 How Student Editors Perform Differently from General Wikipedia Editors?
\f1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\ri0
\cf0 \
# Authors: Yixuan Li (yl2363@cornell.edu), Zheng Yao (zy87@cornell.edu)
\f2 \

\f1 # Date modified: 2015-04-12
\f2 \
\

\f1 \'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
Intro\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\ri0

\f0 \cf0 The package contains data information about 2000 pieces of rumors, crawled from the first 100 pages of Sina Weibo\'92s rumor showcase (http://service.account.weibo.com)
\f2 \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardeftab720\ri0

\f1 \cf0 Helper code \'93weiboLogin\'94 allows the user to log into Sina Weibo with his/her own Weibo account and password. 
\f2 \
\

\f1 \'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
Requirement\
0. Python >= 2.6 (but not 3.x)\
1. BeautifulSoup (http://www.crummy.com/software/BeautifulSoup/)\
2. json
\f2 \

\f1 3. pickle\
4. string\
5. urllib2\
6. re\
\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
How to run the code?\
\
1. Fill in your own Sina Weibo username and password in the main function of \'93rumor_crawler.py\'94 file and save.\
\
    username = '...your username...'\
    pwd = '...your password...'\
\
2. You can modify the starting crawling page and ending crawling page by adjusting the parameters when calling the function of \'93iterate_pages(start,end)\'94. In our code, the default starting page is 1 and ending page is 100.\
\
3. Run the crawler: ``python rumor_crawler.py\'94\
\
\
\
\
\
\

\f2 \
}